# uplas-ai-agents/nlp_content_agent/main.py
from fastapi import FastAPI, HTTPException, BackgroundTasks, status
from pydantic import BaseModel, Field, validator
from typing import List, Dict, Optional, Any, Union
import os
import uuid
import time
import httpx # For any potential future internal calls (not primary for this agent)
import logging
import json

# Assuming shared_ai_libs is accessible in the Python path later.
# For now, defining them here if shared_ai_libs isn't set up.
# from shared_ai_libs.main import SUPPORTED_LANGUAGES, DEFAULT_LANGUAGE
SUPPORTED_LANGUAGES = ["en-US", "fr-FR", "es-ES", "de-DE", "pt-BR", "zh-CN", "hi-IN"] #
DEFAULT_LANGUAGE = "en-US" #


# --- Configuration ---
GCP_PROJECT_ID = os.getenv("GCP_PROJECT_ID") #
GCP_LOCATION = os.getenv("GCP_LOCATION", "us-central1") #
NLP_LLM_MODEL_NAME = os.getenv("NLP_LLM_MODEL_NAME", "gemini-1.5-flash-001") #

# --- Logging Setup ---
logging.basicConfig(level=logging.INFO) #
logger = logging.getLogger(__name__) #

# --- Pydantic Models for NLP Agent Output (Our Structured Educational Gold) ---

class NlpTopic(BaseModel): #
    topic_id: str = Field(default_factory=lambda: f"topic_{uuid.uuid4().hex[:8]}", examples=["topic_superposition_intro"])
    topic_title: str = Field(..., examples=["Understanding Superposition"])
    key_concepts: List[str] = Field(default_factory=list, examples=[
        "Qubits can represent 0, 1, or a combination of both.",
        "Superposition allows quantum computers to perform many calculations at once."
    ])
    content_with_tags: str = Field(..., examples=["A classical bit is either 0 or 1. <analogy type=\"comparison_to_classical_needed\" /> ... <difficulty type=\"foundational_info\" />"])
    # InnovateAI Optional Enhancement: LLM could estimate complexity or suggest pre-requisites
    estimated_complexity_score: Optional[float] = Field(None, ge=0.0, le=1.0, description="Normalized complexity score (0=easiest, 1=hardest)")
    suggested_prerequisites: Optional[List[str]] = Field(default_factory=list, description="List of prerequisite topic names or concept keywords.")


class NlpLesson(BaseModel): #
    lesson_id: str = Field(default_factory=lambda: f"lesson_{uuid.uuid4().hex[:8]}", examples=["lesson_quantum_basics"])
    lesson_title: str = Field(..., examples=["What is a Qubit?"])
    lesson_summary: Optional[str] = Field(None, description="A brief summary of the lesson, generated by LLM.")
    topics: List[NlpTopic] = Field(default_factory=list)


class ProcessedModule(BaseModel): #
    module_id: str = Field(..., examples=["course101_module3_processed"]) # ID of the processed module
    source_module_id: str = Field(..., examples=["course101_module3_raw"]) # ID of the original raw module
    module_title: Optional[str] = Field(None, examples=["Introduction to Quantum Computing"])
    language_code: str = Field(..., examples=["en-US"])
    lessons: List[NlpLesson] = Field(default_factory=list)
    processing_time_ms: Optional[float] = None
    llm_model_used: Optional[str] = None
    # InnovateAI Enhancement: Add a list of all identified visual aid suggestions for the whole module
    module_level_visual_aid_summary: Optional[List[Dict[str,str]]] = Field(default_factory=list, description="Summary of all visual aid suggestions in the module.")

# --- Pydantic Models for API Request ---

class ProcessContentRequest(BaseModel): #
    module_id: str = Field(..., examples=["course101_module3_raw"], description="Unique ID for the raw course module being processed.")
    raw_text_content: str = Field(..., min_length=50, description="The full raw text content of the course module.") # Reduced min_length for flexibility
    language_code: str = Field(DEFAULT_LANGUAGE, examples=SUPPORTED_LANGUAGES)
    module_title: Optional[str] = Field(None, description="Optional title for the module if known.")

    @validator('language_code')
    def validate_language_code(cls, v): #
        if v not in SUPPORTED_LANGUAGES:
            logger.warning(f"InnovateAI Warning: Unsupported language_code '{v}' in ProcessContentRequest. Falling back to default '{DEFAULT_LANGUAGE}'.")
            return DEFAULT_LANGUAGE
        return v

# --- Vertex AI LLM Client Logic (InnovateAI Refined) ---
class VertexAILLMClientForNLP: #
    def __init__(self, model_name: str):
        self.model_name = model_name
        # InnovateAI Note: Initialize Vertex AI platform once, globally if appropriate for the application lifecycle.
        # For a stateless agent like this, initializing per-client or ensuring it's done at app startup is fine.
        if not GCP_PROJECT_ID: #
            logger.error("InnovateAI Critical: GCP_PROJECT_ID not set. Vertex AI LLM client for NLP will fail.")
        else:
            try:
                from google.cloud import aiplatform
                aiplatform.init(project=GCP_PROJECT_ID, location=GCP_LOCATION)
                logger.info(f"InnovateAI: Vertex AI SDK initialized for NLP Agent. Project: {GCP_PROJECT_ID}, Location: {GCP_LOCATION}")
            except Exception as e_init:
                logger.error(f"InnovateAI Critical: Failed to initialize Vertex AI SDK for NLP Agent. Error: {e_init}", exc_info=True)


    async def _call_gemini_api(self, system_prompt: str, user_query: str, is_json_output: bool = True) -> str: #
        """
        InnovateAI Placeholder: Actual call to Gemini API.
        Mugambi, you will replace this with your robust Gemini API call logic,
        ensuring to handle authentication, timeouts, and error responses from the API.
        For JSON output, ensure the Gemini model's GenerationConfig uses 'application/json'
        for response_mime_type.
        """
        logger.info(f"InnovateAI Simulating Gemini API call for NLP. Model: {self.model_name}. JSON Output Requested: {is_json_output}")
        logger.debug(f"InnovateAI NLP System Prompt (sample): {system_prompt[:250]}...")
        logger.debug(f"InnovateAI NLP User Query (sample): {user_query[:250]}...")

        # **** START Call to actual Gemini API to be implemented by Mugambi HERE ****
        # Example (Conceptual - ensure you use async client if main FastAPI is async):
        # from vertexai.generative_models import GenerativeModel, Part, GenerationConfig
        # model = GenerativeModel(self.model_name, system_instruction=[Part.from_text(system_prompt)])
        # generation_config = GenerationConfig(
        #     temperature=0.2, # Lower temp for deterministic structuring
        #     max_output_tokens=8192, # Adjust based on expected output size
        # )
        # if is_json_output:
        #     generation_config.response_mime_type = "application/json"
        #     # If Gemini model supports response_schema for more robust JSON, pass it here.
        #
        # response = await model.generate_content_async( # Use async version
        #     [Part.from_text(user_query)],
        #     generation_config=generation_config
        # )
        # response_text = "".join([part.text for part in response.candidates[0].content.parts if part.text])
        # return response_text
        # **** END Call ****

        # Mocked responses for InnovateAI framework:
        if "segment it into distinct, high-level lessons" in system_prompt: #
            mock_lessons_data = [
                {"lesson_title": "Lesson 1: The Grand Introduction", "text_segment_start_index": 0, "text_segment_end_index": 150},
                {"lesson_title": "Lesson 2: Deep Dive into Mocking", "text_segment_start_index": 151, "text_segment_end_index": 300}
            ]
            return json.dumps(mock_lessons_data)
        elif "Your objectives are to:" in system_prompt and "Divide this lesson snippet into logical topics" in system_prompt: #
            mock_lesson_detail = {
              "lesson_title": "Mocked Lesson from Macro (Enriched)",
              "lesson_summary": "This lesson covers the basics of mocking techniques in InnovateAI.",
              "topics": [{
                  "topic_id": "mock_topic_enriched_1",
                  "topic_title": f"Enriched Mock Topic in lang_placeholder",
                  "key_concepts": ["Concept Alpha", "Concept Beta"],
                  "content_with_tags": "This is enriched content. <analogy type=\"everyday_life\" /> An example is <example domain=\"software_testing\" />. Understand? <interactive_question_opportunity text_suggestion=\"What is a key benefit of mocking?\" /> <visual_aid_suggestion type=\"flowchart\" description=\"Mocking process flowchart\" /> This is <difficulty type=\"intermediate_detail\">quite involved</difficulty>.",
                  "estimated_complexity_score": 0.6,
                  "suggested_prerequisites": ["Basic Unit Testing"]
                }]
            }
            return json.dumps(mock_lesson_detail)
        logger.warning("InnovateAI Mock: No specific mock response matched in _call_gemini_api for NLP.")
        return "{}" # Default empty JSON

    async def macro_segment_module(self, full_text: str, language_code: str, module_title: Optional[str]) -> List[Dict[str, Any]]: #
        """
        InnovateAI: Uses LLM to break the module into high-level lessons.
        Returns a list of lesson titles and their corresponding text segments (character start/end indices).
        """
        system_prompt = ( #
            "You are an expert instructional designer specializing in modular content creation. "
            f"Your task is to analyze the provided course module text, which is in [{language_code}], "
            f"and segment it into distinct, coherent, high-level lessons. Each lesson should represent a significant unit of learning."
            f"For each identified lesson, provide a concise and engaging 'lesson_title' in [{language_code}]. "
            "Also, provide the exact 'text_segment_start_index' (integer, 0-based) and 'text_segment_end_index' (integer, exclusive) "
            "from the original text that constitutes that lesson. "
            f"The overall module is titled: '{module_title if module_title else 'Not Provided'}'. "
            "Focus on logical flow, clear topic transitions, and appropriate lesson lengths for online learning. "
            "Respond ONLY with a valid JSON list of objects. Each object in the list MUST have three keys: "
            "'lesson_title' (string), 'text_segment_start_index' (integer), and 'text_segment_end_index' (integer)."
        )
        user_query = f"Here is the full module text in [{language_code}] to segment into lessons:\n\n---MODULE TEXT START---\n{full_text}\n---MODULE TEXT END---"

        try:
            response_str = await self._call_gemini_api(system_prompt, user_query, is_json_output=True)
            lessons_data = json.loads(response_str)
            if not isinstance(lessons_data, list): # Basic validation
                logger.error(f"InnovateAI Error: LLM response for macro-segmentation was not a list. Response: {response_str[:300]}")
                raise ValueError("LLM response for macro-segmentation was not a list.")
            # InnovateAI: Add more detailed validation for each item in the list
            for item in lessons_data:
                if not all(k in item for k in ("lesson_title", "text_segment_start_index", "text_segment_end_index")):
                    logger.error(f"InnovateAI Error: Invalid item in macro-segmentation list: {item}. Missing required keys.")
                    raise ValueError("Invalid item structure in LLM response for macro-segmentation.")
            return lessons_data
        except json.JSONDecodeError as e: #
            logger.error(f"InnovateAI JSONDecodeError in macro_segment_module: {e}. Response: {response_str[:500]}", exc_info=True)
            raise ValueError(f"Failed to parse LLM response for macro-segmentation: {e}")
        except Exception as e: #
            logger.error(f"InnovateAI Error in macro_segment_module: {e}", exc_info=True)
            raise

    async def micro_segment_and_enrich_lesson(self, lesson_text_snippet: str, lesson_title_from_macro: str, language_code: str) -> Dict[str, Any]: #
        """
        InnovateAI: Uses LLM to break a lesson into topics, identify key concepts, generate a summary,
        and intelligently intersperse the content with enrichment tags.
        """
        system_prompt = ( #
            f"You are an AI pedagogical content specialist. Your current task is to meticulously analyze the following lesson text snippet, "
            f"which is part of a larger lesson titled '{lesson_title_from_macro}'. The text is in [{language_code}]. "
            "Your objectives are to structure and enrich this content:"
            "1. Generate a concise 'lesson_summary' (1-2 sentences) for this entire snippet, in [{language_code}]."
            "2. Divide this lesson snippet into logical, granular 'topics'. For each topic:"
            "   a. Provide a unique 'topic_id' (e.g., 't1_concept_x')."
            "   b. Provide a clear and descriptive 'topic_title' in [{language_code}]."
            "   c. Extract 2-4 crucial 'key_concepts' as a list of short strings, also in [{language_code}]."
            "   d. Provide the 'content_with_tags'. This is the original text for the topic, but you MUST intelligently intersperse it "
            "      with the following XML-like semantic tags where pedagogically appropriate:"
            "      - `<analogy type=\"[general_analogy_needed|technical_analogy_needed|user_profile_analogy_placeholder]\" />` for complex ideas."
            "      - `<example domain=\"[general_example_needed|finance_example_needed|tech_example_needed|user_profile_example_placeholder]\" />` for illustrating points."
            "      - `<interactive_question_opportunity text_suggestion=\"[Suggest a brief checking question in [{language_code}] here]\" />` at points good for engagement/reflection."
            "      - `<visual_aid_suggestion type=\"[diagram_needed|chart_needed|animation_cue|image_idea]\" description=\"[Briefly describe visual in [{language_code}]]\" />` for concepts best shown visually."
            "      - `<difficulty type=\"[foundational_info|intermediate_detail|advanced_detail]\" />` to classify the complexity of content sections."
            "      Ensure these tags are placed naturally within the flow of the text and enhance learning."
            "   e. Optionally, add 'estimated_complexity_score' (float, 0.0 to 1.0) and 'suggested_prerequisites' (list of strings) for each topic."
            "All text content you generate (titles, concepts, summaries, tag suggestions) MUST be in [{language_code}]."
            "Respond ONLY with a single, valid JSON object. The root object should have 'lesson_title' (string, use '{lesson_title_from_macro}'), "
            "'lesson_summary' (string), and 'topics' (list of topic objects as described above)."
        )
        user_query = f"Analyze and enrich this lesson text snippet in [{language_code}]:\n\n---LESSON SNIPPET START---\n{lesson_text_snippet}\n---LESSON SNIPPET END---"

        try:
            response_str = await self._call_gemini_api(system_prompt, user_query, is_json_output=True)
            enriched_lesson_data = json.loads(response_str)
            # Basic validation
            if not isinstance(enriched_lesson_data, dict) or "topics" not in enriched_lesson_data or "lesson_title" not in enriched_lesson_data:
                logger.error(f"InnovateAI Error: LLM response for micro-segmentation lacks 'topics' or 'lesson_title'. Response: {response_str[:300]}")
                raise ValueError("LLM response for micro-segmentation was not a valid lesson structure.")
            # InnovateAI: Further validation on topic structure can be added here.
            for topic in enriched_lesson_data.get("topics", []):
                if not all(k in topic for k in ("topic_id", "topic_title", "key_concepts", "content_with_tags")):
                     logger.warning(f"InnovateAI Warning: A topic in micro-segmentation is missing required keys: {topic.get('topic_id', 'N/A')}")
            return enriched_lesson_data
        except json.JSONDecodeError as e: #
            logger.error(f"InnovateAI JSONDecodeError in micro_segment_and_enrich_lesson: {e}. Response: {response_str[:500]}", exc_info=True)
            raise ValueError(f"Failed to parse LLM response for micro-segmentation: {e}")
        except Exception as e: #
            logger.error(f"InnovateAI Error in micro_segment_and_enrich_lesson: {e}", exc_info=True)
            raise

# Initialize client
nlp_llm_client = VertexAILLMClientForNLP(model_name=NLP_LLM_MODEL_NAME) #

# --- FastAPI Application ---
app = FastAPI( #
    title="Uplas NLP Content Structuring & Augmentation Agent - InnovateAI Enhanced",
    description="Processes raw course content into structured, enriched learning units using Vertex AI, designed by InnovateAI.",
    version="0.2.0" # Incremented version
)

@app.post("/v1/process-course-content", response_model=ProcessedModule, status_code=status.HTTP_200_OK) #
async def process_content_endpoint(request_data: ProcessContentRequest, background_tasks: BackgroundTasks): # BackgroundTasks kept if any heavy post-processing were added
    """
    InnovateAI Enhanced Endpoint: Accepts raw course content, processes it through a
    two-stage NLP pipeline (macro-segmentation then micro-segmentation with enrichment),
    and returns a richly structured, tagged version ready for other Uplas AI agents.
    """
    start_time = time.perf_counter()
    logger.info(f"InnovateAI: Received request to process module_id: {request_data.module_id} in language: {request_data.language_code}")

    if not GCP_PROJECT_ID: #
        logger.error("InnovateAI Critical: NLP service cannot operate without GCP_PROJECT_ID.")
        raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail="NLP service is not properly configured (missing GCP Project ID).")

    final_lessons_processed: List[NlpLesson] = []
    all_visual_aid_suggestions_module_level: List[Dict[str,str]] = []

    try:
        # Stage 1: Macro-segmentation into Lessons
        logger.info(f"InnovateAI Stage 1: Starting macro-segmentation for module: {request_data.module_id}")
        macro_segments = await nlp_llm_client.macro_segment_module( #
            request_data.raw_text_content,
            request_data.language_code,
            request_data.module_title
        )
        logger.info(f"InnovateAI Stage 1: Macro-segmentation complete. Found {len(macro_segments)} potential lessons.")

        # Stage 2: Micro-segmentation & Enrichment for each lesson segment
        for i, segment_info in enumerate(macro_segments): #
            lesson_title_from_macro = segment_info.get("lesson_title", f"Lesson {i+1} (Title N/A)")
            start_idx = segment_info.get("text_segment_start_index")
            end_idx = segment_info.get("text_segment_end_index")

            if start_idx is None or end_idx is None or not isinstance(start_idx, int) or not isinstance(end_idx, int) or start_idx >= end_idx : #
                logger.warning(f"InnovateAI Warning: Skipping invalid segment (bad indices): {segment_info} for module {request_data.module_id}")
                continue

            lesson_text_snippet = request_data.raw_text_content[start_idx:end_idx]
            if not lesson_text_snippet.strip(): #
                logger.info(f"InnovateAI Info: Skipping empty lesson text snippet for lesson: {lesson_title_from_macro}")
                continue

            logger.info(f"InnovateAI Stage 2: Starting micro-segmentation for lesson: '{lesson_title_from_macro}'")
            enriched_lesson_data_dict = await nlp_llm_client.micro_segment_and_enrich_lesson( #
                lesson_text_snippet,
                lesson_title_from_macro,
                request_data.language_code
            )
            
            current_lesson_topics_processed: List[NlpTopic] = []
            for topic_data_dict in enriched_lesson_data_dict.get("topics", []): #
                try:
                    # Extract visual aid suggestions from this topic's content_with_tags for module-level summary
                    # This requires a utility to parse these tags if not already structured by LLM
                    # For simplicity, assume NLP agent now focuses on creating the tags, consumer (TTV) parses them.
                    # However, we can collect the visual_aid_suggestion tag content here.
                    # Example: if topic_data_dict["content_with_tags"] contains '<visual_aid_suggestion type="chart" description="Sales trend"/>'
                    # we'd extract {"type": "chart", "description": "Sales trend"}
                    # This logic would need a robust tag parser.
                    # For now, let's assume the description part of visual_aid_suggestion is what we'd collect.

                    processed_topic = NlpTopic(
                        topic_id=topic_data_dict.get("topic_id", f"topic_gen_{uuid.uuid4().hex[:6]}"),
                        topic_title=topic_data_dict.get("topic_title", "Untitled Topic"),
                        key_concepts=topic_data_dict.get("key_concepts", []),
                        content_with_tags=topic_data_dict.get("content_with_tags", ""),
                        estimated_complexity_score=topic_data_dict.get("estimated_complexity_score"),
                        suggested_prerequisites=topic_data_dict.get("suggested_prerequisites", [])
                    )
                    current_lesson_topics_processed.append(processed_topic)
                except Exception as e_topic_val:
                    logger.warning(f"InnovateAI Warning: Failed to validate/process a topic: {topic_data_dict.get('topic_id', 'N/A')}. Error: {e_topic_val}", exc_info=True)
            
            final_lesson_title = enriched_lesson_data_dict.get("lesson_title", lesson_title_from_macro) #
            lesson_summary_from_llm = enriched_lesson_data_dict.get("lesson_summary")

            final_lessons_processed.append(NlpLesson( #
                # lesson_id will be auto-generated by Pydantic model
                lesson_title=final_lesson_title,
                lesson_summary=lesson_summary_from_llm,
                topics=current_lesson_topics_processed
            ))
            logger.info(f"InnovateAI Stage 2: Micro-segmentation for lesson '{final_lesson_title}' complete. {len(current_lesson_topics_processed)} topics processed.")

    except ValueError as ve: #
        logger.error(f"InnovateAI ValueError during content processing for {request_data.module_id}: {ve}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Error processing content: {str(ve)}")
    except Exception as e: #
        logger.error(f"InnovateAI Unexpected error during content processing for {request_data.module_id}: {e}", exc_info=True)
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"An unexpected error occurred during content processing: {str(e)}")

    if not final_lessons_processed: #
        logger.warning(f"InnovateAI Warning: No lessons were successfully processed for module: {request_data.module_id}. This might indicate issues with content or LLM responses.")
        # Depending on requirements, could raise an error or return an empty list.

    end_time = time.perf_counter()
    processing_time_ms = (end_time - start_time) * 1000 #

    logger.info(f"InnovateAI: Successfully processed module_id: {request_data.module_id}. Time taken: {processing_time_ms:.2f} ms. Generated {len(final_lessons_processed)} lessons.")
    return ProcessedModule( #
        # module_id will be auto-generated
        source_module_id=request_data.module_id,
        module_title=request_data.module_title,
        language_code=request_data.language_code,
        lessons=final_lessons_processed,
        processing_time_ms=round(processing_time_ms, 2),
        llm_model_used=nlp_llm_client.model_name
        # module_level_visual_aid_summary would be populated if we extracted them above
    )

# --- Health Check Endpoint ---
@app.get("/health", status_code=status.HTTP_200_OK) #
async def health_check():
    if not GCP_PROJECT_ID or not NLP_LLM_MODEL_NAME: #
        return {"status": "unhealthy", "reason": "Required configurations (GCP_PROJECT_ID, NLP_LLM_MODEL_NAME) are missing.", "service": "NLP_Content_Agent_InnovateAI"}
    # Check if Vertex AI client initialized successfully (conceptual, actual check might involve a quick test call if feasible)
    if nlp_llm_client is None or not hasattr(nlp_llm_client, 'model_name'): # Basic check
         return {"status": "unhealthy", "reason": "Vertex AI client for NLP not properly initialized.", "service": "NLP_Content_Agent_InnovateAI"}
    return {"status": "healthy", "service": "NLP_Content_Agent_InnovateAI", "innovate_ai_enhancements_active": True}

if __name__ == "__main__": #
    import uvicorn
    logger.info("InnovateAI: Starting NLP Content Structuring & Augmentation Agent for local development...")
    if not GCP_PROJECT_ID: #
        print("InnovateAI Warning: GCP_PROJECT_ID is not set. Please set this environment variable for the NLP agent.")
    
    port = int(os.getenv("PORT", 8005)) #
    uvicorn.run(app, host="0.0.0.0", port=port)
